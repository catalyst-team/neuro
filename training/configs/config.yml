model_params:
  model: UNet
  n_channels: 1
  n_classes: 106
args:
  expdir: "./training"
  logdir: "./logs"

runner_params:
  input_key: "images"  # Пример
  output_key: "logits"  # Пример
  input_target_key: "labels"

distributed_params:  # OPTIONAL KEYWORD, параметры для distributed training и NVIDIA Apex
  rank: 0 # Rank для distributed training
  opt_level: O1  # Пример для NVIDIA Apex
  syncbn: False

stages:
  state_params:
    main_metric: &reduce_metric dice
    minimize_metric: False

  data_params:
    num_workers: 2
    batch_size: 1
    in_csv_train: "./data/dataset_train.csv"
    in_csv_valid: "./data/dataset_valid.csv"
    in_csv_infer: "./data/dataset_infer.csv"
    n_samples: 100
    max_batch_size: 3
    subvolume_shape: [64, 64, 64]
    volume_shape: [256, 256, 256]

  criterion_params:
    criterion: DiceLoss

  stage1:
    state_params:
      num_epochs: 100

    optimizer_params:
      optimizer: Adam
      lr: 0.01
      weight_decay: 0.0001

    scheduler_params:
      scheduler: CosineAnnealingWarmRestarts
      T_0: 30
      T_mult: 2
      eta_min: 1e-10

    callbacks_params:
      loss_dice:
        callback: CriterionCallback
        input_key: labels
        output_key: logits
        prefix: &loss loss_dice
      dice_metric:
        callback: DiceCallback
        input_key: labels
        output_key: logits
      optimizer:
        callback: OptimizerCallback
        loss_key: *loss
        accumulation_steps: 8
      scheduler:
        callback: SchedulerCallback
      saver:
        callback: CheckpointCallback
